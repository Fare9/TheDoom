---
layout: post
title: Advanced Programming in the UNIX Environment
date: 2020-01-30 00:12:00
categories: posts
comments: true
en: true
description: Summary Post about Advanced Programming in the UNIX Environment
keywords: "ELF, Unix, POSIX, C, Programming"
authors:
    - Fare9
---

# Advanced Programming in the UNIX Environment (APUE)

## Chapters

1. [Chapter1](#chapter1)
2. [Chapter2](#chapter2)
3. [Chapter3](#chapter3)

# <a name="chapter1"></a> 1 - UNIX System Overview

**Makefile for this chapter [Makefile](https://github.com/K0deless/TheDoom/blob/master/code/APUE/chapter1/Makefile)**

## Introduction
Operating systems offer services for programs they run. Executing a new program, opening a file, reading a file, allocating a memory region, etc.

## Unix Architecture
Operating system software that controls the hardware resources of computer, provides environment where programs can run. This software is called the kernel.
Interface to kernel is a layer of software called "system calls". And libraries of common functions are built on top of system call interface, application are free to use both. Shell is special application that provides interface for running other applications.

Operating system = kernel + system utilities, applications, shells, libraries.

## Login In

**Login Name:**

At login we give login name and password. System checks name and password in the file /etc/shadow. Our entry in the /etc/shadow is composed by different fields separated by colon: login name, encrypted password, user ID, group ID, comment field, home directory, and shell.
We'll see in different chapters how to access to the files.

## Shells
command line interpreter that reads user input and executes commands. User input to a shell is from the terminal (interactive shell) or from a file (shell script). Common shells: bourne shell (/bin/sh), Bourne-again shell (/bin/bash), C shell (/bin/csh), Korn Shell (/bin/ksh), TENEX C shell (/bin/tcsh).
Depending on system, one or another shell will be implemented.

## Files and Directories

**File System**

UNIX file system is hierarchical arrangement of directories and files. Everything starts in directory root (/).
Directory = file that contains directory entries. Each directory entry as containing a filename along with structure of information describing the attributes of the file. The attributes of file are: type of file (regular or directory), size of file, owner of file, permissions for file (whether other users may access this file), and when the file was last modified. "stat" and "fstat" functions return structure of information containing all attributes of a file.
In chapter 4, we'll see distinction between logical view of directory entry and way it's stored on disk. Most UNIX file systems don't store attributes in directory entries themselves, because of difficulty of keeping them in synch when file has multiple hard links.

*Filename* = names in directory. Only two characters cannot be in filename are slash (/) and null. Slash separates filenames that form pathname and null character terminates pathname. Good practice restrict characters in a filename to subset of normal printing characters. POSIX.1 recommends restricting filenames to following characters: letters (a-z,A-Z), numbers (0-9), period (.), dash (-) and underscore (_).
Two filenames created when new directory is created: . (dot) and .. (dot-dot). Dot refers to current directory, dot-dot refers to parent directory. In "root" dot and dot-dot are the same.

*Pathname* = one or more filenames, separated by slashes, optionally starting with a slash, forms a "pathname". Pathname that begins with slash called "absolute pathname"; otherwise "relative pathname". Latter one refer to files relative to current directory. Name for root of file system (/) is special-case absolute pathname that has no filename component.

Example: [my_ls.c](https://github.com/K0deless/TheDoom/blob/master/code/APUE/chapter1/my_ls.c)

In UNIX manual pages can be referenced by numbers, because more than one entry can exists, sections are normally numbered 1 through 8. For example the tool "ls" we've "copied" can be checked in manual as:

```console
    $ man 1 ls
```

or

```console
    $ man -s1 ls
```

If we name the source file as "my_ls.c" we can compile it into the default a.out with the C compiler "CC" as:

```console
    CC my_ls.c
```

From this program we can detail the next:

1. Included one APUE header apue.h. Included in almost every program in book. Header includes some standard system headers and define numerous constant and function prototypes.
2. We include system header dirent.h, to pick up function prototypes for opendir and readdir, in addition to definition of dirent structure. In some systems prototypes and definition of the structure are separated.
3. Declaration of main uses style supported by ISO C standard.
4. We take an argument from command line, argv[1], as name of the directory to list.
5. Because of actual format of directory entries varies from one UNIX to another, we use opendir, readdir and closedir to manipulate directory.
6. opendir function returns pointer to DIR structure, and we pass pointer to readdir function. We don't care about that DIR structure. We give it to readdir in a loop, to read each directory entry. readdir function returns a pointer to direct structure or, when it's finished with directory, a null pointer. We just take the name of the file (d_name).
7. We use two functions of our handle of errors: err_sys and err_quit. The function err_sys prints an informative message describing what type of error was encountered ("Permission denied" or "Not a directory").
8. When program is done, it calls the function exit with argument of 0. Function exit terminates a program. By convention, an argument of 0 means OK, and an argument between 1 and 255 means error ocurred. This value can be retrieved from a shell in variable $?.

**Working Directory:**
every process has working directory, sometime called "current working directory". This is directory from which relative pathnames are interpreted. Process can change working directory with chdir function. Relative pathname doc/memo/joe refers to file or directory joe, in directory memo, which must be a directory within the working directory. Looking just at pathname, we know that doc and memo have to be directories, but we can't tell if joe is file or directory. Pathname /usr/lib/lint is absolute path, refers to file or directory lint in directory lib, in directory usr, which is in root.

**Home directory:**
The working directory is set to our home directory. Obtained from our entry in password file.

## Input and Output

**File Descriptors:**

normally small non-negative integers, kernel uses to identify files accessed by process, opening existing or creating a file, kernel returns file descriptor, we use when we want to read or write file.

Standard Input, Standard Output, and Standard Error:

By convention, all shells open three descriptors when program runs: standard input, standard output, and standard error. For a command like:

```console
    $ ls
```
three are connected to terminal. Shells provide a way of redirection:

```console
    $ ls > file.list
```

redirects standard output to a file named file.list.

**Unbuffered I/O:**

provided by functions open, read, write, lseek and close. These work with file descriptors.

Example: program to read from standard input and wirte to standard output. [stdin_to_stdout.c](https://github.com/K0deless/TheDoom/blob/master/code/APUE/chapter1/stdin_to_stdout.c)

Header <unistd.h> included by apue.h, and constants STDIN_FILENO and STDOUT_FILENO are part of POSIX standard. Header contains function prototypes for many UNIX system services, such as read and write functions.
Contants STDIN_FILENO and STDOUT_FILENO are in <unistd.h> and specify file descriptors for standard input and standard output, values are 0 and 1, respectively, we will use names for readability.
Section 3.9 we'll examine BUFFSIZE constant.
read function returns number of bytes that are read, value is used as number of bytes to write. When end of file is encountered, read returns 0 and program stops. If error ocurris, read returns -1 (as many system functions).
Executing file as:

```console
   $ ./stdin_to_stdout > data
```
standard input will be the terminal, and standard output is redirected to file data, and standard error is also terminal. If output file doesn't exist, shell creates it by default. Program copy bytes until we type end-of-file character (CTRL+D).
If we run:

```console
    $ ./stdin_to_stdout < infile > outfile
```

then file named infile will be copied to file named outfile.

In chapter 3 we will see unbuffered I/O more detail.

**Standard I/O:**

buffered interface to the unbuffered I/O functions. Using standard I/O relieves us from having to choose optimal buffer sizes. Standard I/O simplify dealing with lines of input (common ocurrence in UNIX applications). fgets function, reads entire line. The read function, in contrast, reads a specifed number of bytes. Standard I/O library provide functions that let us control style of buffering used by library.
Most common standard I/O function is printf. For those programs we will include <stdio.h> (included by apue.h), header contains function prototypes for all standard I/O functions.

Example: [standard_stdin_to_stdout.c](https://github.com/K0deless/TheDoom/blob/master/code/APUE/chapter1/standard_stdin_to_stdout.c) . Like previous program, program copies standard input to standard output and copy any regular file. Function getc used reads one character at a time, and character is written by putc, after last byte of input has been read, getc returns constant EOF (defined in <stdio.h>). Standard I/O constant stdin and stdout are also defined in <stdio.h> which refers to standard input and standard output.

## Programs and Processes

**Program:**
executable file residing on disk in directory. Program is read into memory and executed by kernel as result of one of seven exec functions.

**Processes and Process ID:**
executing instance of a program is called a process. Some operating system  use term task to refer a program being executed. UNIX system guarantees every process has a unique numeric identifier called process ID. Process ID is always a non-negative integer.

example: [print_pid.c](https://github.com/K0deless/TheDoom/blob/master/code/APUE/chapter1/print_pid.c) example program that prints the pid of the running process calling the function getpid, it returns a pid_t data type. We don't know size, but standards guarantee that it will fit in a long integer. We cast it to the largest data type that it might use (long integer). Although most process IDs will fit in a int, using a long promotes portability.

**Process Control:**
Three primary functions for process control: fork, exec and waitpit (exec function has seven variants, but we refer all of them as exec function).

Example: [very_simple_shell.c](https://github.com/K0deless/TheDoom/blob/master/code/APUE/chapter1/very_simple_shell.c) example of process control features demonstrated on simple program, reads commands from standard input, and executes commands. Bare-bones implementation of shell-like program.

Several features to consider in that little program. We use standard I/O fgets to read one line at a time from standard input. When we type end-of-file character (often CTRL+D) as first character of a line, fgets returns null pointer, loop stops, and process terminates. In chapter 18, we'll see all special terminal characters (end of file, backspace one character, erase entire line). Because each line returned by fgets is terminated with newline character, followed by null byte, we use standard C function strlen to calculate length of the string, then replace newline with null byte. This is done for execlp working properly. We call fork to create new process, which is a copy of caller. Caller is the parent and the newly created process is the child. fork returns: non-negative PID of new child process to parent, and 0 to the child.
In the child, we call execlp to execute command read from standard input. Replaces child process with new program file. Combination of fork + exec is called spawning a new process. In UNIX, the two parts are separated by individual functions (we'll talk more about that in Chapter 8).
Because of child process calls execlp to execute new program, parent should wait until child terminate. Done by calling waitpid, specifying which process to wait for: pid argument, which is process ID of child. waitpid returns termination status of child process (status variable), we don't do anything with that, but we could examine it to determine how child terminated.
Most fundamental limitation of program, we can't pass arguments to command we execute. We can't, specify name of a directory list. We can execute ls only in working directory. To allow arguments would require we parse input line, separating arguments as separate parameter to execlp function.

**Threads and Thread IDs:**

Usually 1 process = 1 thread, one set of machine instructions executing at a time. Some problems are easier to solve when more than one thread can operate on different parts of problem. Additionally, multiple threads of control can exploit parallelism possible on multiprocessor systems.
All threats within a process share same address space, file descriptors, stacks and process-related attributes. Each thread executes on its own stack, although any thread can access stacks of other threads. Because of access to same memory, threads need to synchronize access to shared data to avoid inconsistences.
Like processes, threads are identified by IDs. Thread IDs, however, are local to a process. A thread ID from one process has no meaning in another process. We use thread IDs to refer to specific threads as we manipulate threads within a process.
We'll see more in Chapter12 about thread parallelism and process parallelism.

## Error Handling

Error occurs in one UNIX System function, negative value often returned, integer errno, usually set to value tells why. Example, open function returns a non-negative file descritor if all is OK or -1 if error ocurrs. Error from open = about 15 possible errno values (files doesn't exist, permission problem, and so on). Some functions use a convention other than returning a negative value. Most functions that return pointer to object return null pointer to indicate error.
File <errno.h> defines symbol errno, constants for each value errno can assume. Each of the constants starts with character E. Also first page of section 2 of UNIX system manuals, named intro(2) lists all these error constants. Example if errno is equal to constant EACCES, indicates permission problem, such as insufficient permission to open requested file (On Linux, error constants are listed in errno(3)). POSIX and ISO C define errno as symbol expanding into modificable lvalue of type integer. Can be integer that contains error number or function that returns pointer to error number. Definition:     extern int errno;
In environment that supports threads, process address space is shared among multiple threads, each thread needs own local copy of errno. Linux supports multithreaded access to errno defining it as:
        extern int *__errno_location(void);
        #define errno (*__errno_location())
Two rules to be aware of with respect to errno. First: value is never cleared by a routine if error doesn't occur. We should examine its value only when return value indicates an error ocurred. Second, value of errno is never set to 0 by any of functions, none of constants defined in <errno.h> has value of 0.

Also two functions are defined by C standard to help with printing error messages.
```C
    #include <string.h>
    char *strerror(int errnum);     // returns: pointer to message string
```
Function maps errnum, typically errno value, into an error message string and returns a pointer to string.
perror function produces error message on standard error, based on current value of errno, and returns.

```C
    #include <stdio.h>
    void perror(const char *msg);
```
outputs the string pointed to by msg, followed by a colon and a space, followed by error message corresponding to value of errno, followed by newline.

Example: [print_error.c](https://github.com/K0deless/TheDoom/blob/master/code/APUE/chapter1/print_error.c) this program we'll see the use of strerror, and perror with common error numbers. Note we pass the name of the program (argv[0], whose value is ./print_error as argument to perror. Standard convention in UNIX system, doing this, if program is executed as part of pipeline, we are able to tell which of three programs generated a particular error. Instead of calling strerror or perror, we will use the error functions from appendix B. These functions let us use variable argument list facility of ISO C to handle error conditions with single C statement.

**Error recovery:**

errors in <errno.h> can be divided into two categories: fatal and nonfatal. fatal error has no recovery. Best we can do, print error message on user's screen or to log file, then exit. Nonfatal errors, can sometimes be dealt with more robustly. Most nonfatal errors are temporary, such as resource shortage, might not occur when there's less activity on system.
Resource-related nonfatal erros: EAGAIN, ENFILE, ENOBUFS, ENOLCK, ENOSPC, EWOULDBLOCK, and sometimes ENOMEM. EBUSY can be treated as nonfatal, indicates that shared resource is in use. Sometimes, EINTR can be treated as nonfatal error when it interrupts a slow system call.
Typical error recovery action, for resource-related non fatal error, delay and retry later. Can be used for example if an error indicates, a network connection is no longer functioning, it might be for application to delay a short time, then reestablish connection. Some applications use exponential backoff algorithm, waiting longer in each subsequent iteration.
Ultimately, it is up to application developer determine cases where application can recover from an error. If reasonable recovery strategy can be used, we can improve robustness of our application by avoiding an abnormal exit.

## User Identification

**User ID:**

numeric value that identifies us to system. User ID assigned by system administrator when our login name is assigned, we cannot change it. User ID normally assigned to be unique for every user. We'll see how kernel uses user ID to check whether we have appropiate permissions to perform certain operations.
User ID with ID = 0 is root or superuser. Entry in password file normally has login name of root, we refer to special privileges of this user as superuser privileges. We'll see in Chapter 4, if process has superuser privileges, most file permission checks are bypassed. Some operating system functions are restricted to superuser. Superuser has free rein over the system.
Mac OS X comes with superuser account disabled; server versions ship with account enabled. Apple's website show how to enable it.

**Group ID:**

our entry in password file also specifies numeric group ID. This is asigned by system administrator when our login name is assigned. Typically, password file contains multiple entries that specify same group ID. Groups normally used to collect users together into projects or departments. Allows sharing of resources, such as files, among members of same group. We'll see that we can set permissions on a file so all members of a group can access file, whereas others outside group cannot.
There's group file that maps group names into numeric group IDs. Group file usually in /etc/group.
Use of numeric IDs and numeric group IDs for permissions is historical. For every file, file system stores UID and GID of file's owner. Storing both requires only four bytes, assuming each is 2-byte integer. If full ASCII login name and group name were used, additional disk space would be required. Also comparing strings during permission checks is more expensive than comparing integers.
Users work better with names than numbers, so password file maintains mapping between login names and UIDs, and group file provides mapping between group names and GIDs. ls -l command, prints login name of owner of a file, using password file to map numeric user ID into corresponding login name (early UNIX used 16-bit integer for UIDs and GIDs, current UNIX systems use 32-bit integers).

Example: [get_ids.c](https://github.com/K0deless/TheDoom/blob/master/code/APUE/chapter1/get_ids.c) program to see user ID and group ID of process owner (user which executes the program).

**Supplementary Group IDs:**

addition to GID specified in password file for login name, UNIX system allow user to belong other groups. Practice started with 4.2BSD, which allowed user to belong to up to 16 additional groups. Supplementary group IDs are obtained at login time reading the file /etc/group, and finding first 16 entries that list user as a member. As we will see in next chapter, POSIX requires system support at least 8 supplementary groups per process, but most systems support at least 16.

## Signals

technique used to notify a process some condition has occurred. If a process divides by zero, signal SIGFPE (floating-point exception) is sent to process. Process has three choices for dealing with signal.
1. Ignore signal. Option isn't recommended for signals that denote a hardware exception, such as dividing by zero or referencing memory outside the address space of the process, as the results are undefined.
2. Let default action occur. For a divide-by-zero condition, default is to terminate the process.
3. Provide a function that is called when signal occurs (this is called "catching" signal). By providing a function of our own, we'll know when signal occurs and we can handle it as we wish.

Many conditions generate signals. Two terminal keys, called interrupt key (often the DELETE key or CTRL-C) - and the quit key - often CTRL-backslash - are used to interrupt currently running process. Another way to generate a signal is calling the kill function. We can call this function from process to send a signal to another process. There are limitations: we have to be owner of the other process (or superuser) to be able to send it a signal.

Example: [sig_int_catch.c](https://github.com/K0deless/TheDoom/blob/master/code/APUE/chapter1/sig_int_catch.c) Recall bare-bones example (very_simple_shell.c). If we invoke program and press interrupt key, process terminates because default action for signal named SIGINT, is to terminate process. Process hasn't told kernel to do anything other than default with signal, so process terminates.
To catch signal, program needs to call signal function, specifying name of the function to call when SIGINT signal is generated. Function is named sig_int; when it's called, just prints a message and a new prompt. Adding 11 lines to the program in very_simple_shell.c.

## Time Values
UNIX systems have maintained two different time values:
        1. Calendar time. Value counts number of seconds since Epoch: 00:00:00 January 1, 1970, UTC. These time values are used to record time when file was last modified. Primitive system data type time_t holds these time values.
        2. Process time. Also caled CPU time, measures central processor resources used by a process. Process time is measured in clock ticks, typically 50, 60 or 100 ticks per second. The primitive data type clock_t holds these time values. We'll see how to get that function in section 2.5.4 with function sysconf.

When we measure execution time of process, as in Section 3.9, we'll see UNIX System maintains three values for process:

+ Clock time
+ User CPU time
+ System CPU time

Clock time (or wall clock time), amount of time process takes to run, value depends on number of other processes being run on system. Whenever we report clock time, measurements are made with no other activities on system.
User CPU time, is CPU time attributed to user instructions. System CPU is time attributed to kernel when it executes on behalf of the process. Example, whenever a process executes a system service (read or write), time spent within kernel performing that system service is charged to process. Sum of user CPU time and system CPU is often called CPU time.
It is easy to measure clock time, user time, and system time using the command "time(1)", with argument to time command being command we want to measure. Example:

```console
    $ time -p grep _POSIX_SOURCE */*.h > /dev/null

    real 0m0.81s
    user 0m0.11s
    sys  0m0.07s
```

Output format from time command, depends on shell being used, because some shells don't run /usr/bin/time, instead have a separate built-in function to measure time it takes commands to run.
Section 8.17, we'll see how to obtain these three times from a running process. General topic of times and dates is covered in Section 6.10.

## System Calls and Library Functions

All operating systems provide service points through which programs request services from kernel. UNIX implementations, provides limited number of entry points directly into kernel called system calls. Version 7 Research UNIX System provided 50 syscalls, 4.4BSD about 110, and SVR4 has around 120. More recent systems have seen incredible growth in number of supported syscalls. Linux 3.2.0 has 380 syscalls, and FreeBSD 8.0 over 450.
System call interface always has been documented in Section 2 of UNIX Programmer's Manual. Its definition is in C language, no matter implementation technique is used to invoke a system call. This differs from many older operating systems, which defined kernel entry point in assembly language of the machine. For our purposes, we can consider syscalls to be C functions.
Section 3 of UNIX Programmer's Manual defines general-purpose library functions available to programmers. Functions aren't entry points into kernel, although they may invoke one or more of kernel's system calls. Example, printf may use to write system call to output a string, but strcpy (copy a string) and atoi (ASCII to integer) don't involve kernel at all.

From implementor's point of view, distinction between system call and library function is fundamental. From user's perspective, difference is not as critical. From our perspective, both system calls and library functions appear as normal C functions. Both exist to provide services for application programs. We should realize, that we can replace library functions, whereas system calls usually cannot be replaced.
Consider memory allocation function "malloc". There are many ways to do memory allocation and its garbage collection. UNIX system call that handles memory allocation, sbrk, is not general-purpose memory manager. Increases or decreases address space of process by specified number of bytes. How space is managed is up to process. Memory allocation function, malloc(3), implements one particular type of allocation. If we don't like operation, we can define own malloc function, which will probably use sbrk system call. In fact, numerous software packages implement their own memory allocation algorithms with sbrk syscall.
System call in kernel allocates additional chunk of space on behalf of the process. malloc library function manages space from user level.
Another example between syscall and library function, UNIX System interface to determine current time and date. Some OSs provide one syscall to return time and another return the date. Any special handling, such as switch to or from daylight saving time, handled by kernel or requires human intervention. UNIX System, provides single syscall that returns number of seconds since Epoch: 00:00, January 1, 1970, UTC. Any interpretation of value, such as converting it to human-readable time and date using local time zone, is left to user process. Standard C library provides routines to handle most cases.
Another difference is that syscalls usually provide minimal interface, whereas library often provide more elaborate functionality. We've seen this in difference between sbrk syscall and malloc function. We'll see this also when we compare unbuffered I/O functions (Chapter 3) and standard I/O functions (Chapter 5).
Process control syscalls (fork, exec and waitpid) usually invoker by user's application code directly. But some library routines exist to simplify certain common cases: system and popen library routines. We'll show implementation of system function that invokes basic process control syscalls.
To define interface to UNIX System that most programmers use, we have to describe system calls and some of library functions. If we described only sbrk system call, we would skip more programmer-friendly malloc library that many applications use. We will use the term function to refer both syscalls and library functions, except when distinction is necessary.

# <a name="chapter2"></a> 2 - UNIX Standardization and Implementations

Mostly tables, and enumerations from POSIX's standards. There are also some type limits from POSIX and standard C and other different constants, there isn't code really so you can take a quick look to it.
Some functions listed here are: sysconf, pathconf, fpathconf.
You have also pathname limits, maximum number of open files, primitive system data types listed in header "<sys/types.h>" and finally differences between standards.

# <a name="chapter3"></a> 3 - File I/O

**Makefile for this chapter [Makefile](https://github.com/K0deless/TheDoom/blob/master/code/APUE/chapter3/Makefile)**

## Introduction

Start discussion of UNIX System describing functions available for file I/O-- open, read, write a file and so on. Most file I/O on UNIX system can be performed using five functions: open, read, write, lseek and close. We then examine effect of various buffer sizes on read and write functions.
Functions described in chapter are often referred to as unbuffered I/O, in contrast to standard I/O routines, which we describe in Chapter 5. Term unbuffered means each read or write invokes syscall in kernel. Unbuffered I/O functions are not part of ISO C, are part of POSIX.1 and Single UNIX Specification.
Whenever we describe sharing of resources among multiple processes, concept of atomic operation becomes important. We examine concept with regard to file I/O and arguments to open function. This leads to discussion of how files are shared among multiple processes and which kernel data structures are involved. After describing features, we describe dup, fcntl, sync, fsync and ioctl functions.

## File Descriptors

To kernel, all open files are file descriptors. File descriptor is non-negative integer. When open existing file or create new one, kernel returns file descriptor to process. When we want to read or write a file, we identify file with file descritor returned by open or creat, as argument to read or write.
By convention, UNIX shells associate file descriptor 0 as standard input, 1 as standard output, and 2 as standard error of process. Convention used by shells and many applications; not feature of UNIX kernel. Many application would break if associations weren't followed.
Values are standardized by POSIX.1, but magic numbers (0,1 and 2) should by replaced in POSIX-compliant apps to symbolic constants STDIN_FILENO, STDOUT_FILENO, and STDERR_FILENO to improve readability, constants defined in <unstid.h> header.
File descriptors goes from 0 to OPEN_MAX - 1. Early historical implementations of UNIX had opper limit of 19, allowing maximum of 20 open file per process, may systems increases limit to 63.

## open and openat Functions

File created or opened using any of these functions:
```C
	int open (const char *path, int oflag, ... /* mode_t mode */ );
	int openat (int fd, const char *path, int oflag, ... /* mode_t mode */ );

	Both return: file descriptor if OK, -1 on error.
```

We show last argument as ..., ISO C way to specify number and types of remaining arguments may vary. For these functions, last argument used only when new file is being created. We show argument as comment in prototype.
path parameter is name of file to open or create. Function has multitude of options, specified by oflag argument. Argument is formed by ORing together one or more of following constants from <fcntl.h> header:

```
	O_RDONLY	open for reading only
	O_WRONLY	open for writing only
	O_RDWR		open for reading and writing
	O_EXEC		open for execute only
	O_SEARCH	open for search only (for directories)

	this one is used to evaluate search permission at time
	a directory is opened, further operations using directory's
	file descriptor will not reevaluate permission
	to search.
```

One and only one of previous five constants must be specified, next will be optional:
```
	O_APPEND	appent to end of file on each write.
	O_CLOEXEC	set FD_CLOEXEC file descriptor flag.
	O_CREATE	Create file if it doesn't exist, option requires third argument to open function, mode, which specifies access permission bits of new file. We'll see how it can be modified by umask value of process.
	O_DIRECTORY	Generate error if path doesn't refer to directory
	O_EXCL		Generate error if O_CREAT also specified file and file exists. This test if file already exists and creation of file if it doesn't exist is an atomic operations. We'll see
	O_NOCTTY	If path refers to terminal device, don't allocate device as controlling terminal for this process. We'll see in chapter 9
	O_NOFOLLOW	Generate error if path refers to symbolic link.
	O_NONBLOCK	If path refers to FIFO, a block special file, or character special file, this option sets nonblocking mode for both opening of file and subsequent I/O.
	In releases of System V, O_NDELAY (no delay) flag was introduced. SImilar to O_NONBLOCK option, but ambiguity was introduced in return value from read operation. no-delay causes a read operation return 0 if no data to be read from pipe, FIFO or device, but conflicts with return value of 0, indicating end of file. SVR4-based system still support no-delay, but nw apps should use nonblocking option instead
	O_SYNC		Make each write wait for physical I/O to complete, including I/O necessary update file attributes modified as result of write.
	O_TRUNCT	If file exists and if opened for either write-only or read-write, truncate length to 0.
	O_TTY_INIT	When opening terminal device not already open, set nonstandard termios parameters to values that result in behavior that conforms Single UNIX Specification. We'll see in chapter 18.
```

Following two flags are also optional. They are part of synchronized input and output options of Single UNIX Specification.
```
	O_DSYNC		Make each write wait for physical I/O to complete, but don't wait for file attributes to be updated if they don't affect ability to read data just written. In O_DSYNC affects a file's attributes only when they need to be updated to reflect change in file's data. With O_SYNC flag, data and attributes are always updated synchrnously.
	O_RSYNC		Make each read operation on file descriptor wait until any pending wirtes for same portion of file are complete.
```

File descriptor returned by open and openat guaranteed to be lowest-numbered unused descriptor. This fact used by some applications to open new file on standard input, standard output, or standard error. Example, application might close standard output (normally, file descriptor 1) then open another knowing that it will be opened on file descriptor 1. We'll see better way to guarantee that file is open on given descriptor, with the function "dup2" (better than "dup").

*fd* parameter distinguishes openat function from open function. There are three possibilities:

1. path parameter specifies an absolute pathname. This case, fd parameter is ignored and openat functions behaves like open function.
2. path parameters specified relative pathname and fd parameter is file descriptor that specifies starting location in file system where relative pathname is to be evaluated. fd parameter obtained by opening the directory where relative pathname is to be evaluated.
3. path parameter specified a relative pathname and fd parameter has special value AT_FDCWD. This case, pathname is evaluated starting in current working directory and openat function behaves like open function.

*openat* function is one of a class of functions added to latest version of POSIX.1 to address two problems. First, gives threads way to use relative pathnames to open files in directories other than current working directory. All threads share same current working directory, so makes it difficult for multiple threads in same process to work in different directories at same time. Second, it provides a way to avoid time-of-check-to-time-of-use (*TOCTTOU*) errors.

*TOCTTOU* errors program vulnerable if it makes two file-based function calls where second call depends on result of first call. Because two calls are not atomic, file can change between the two calls, thereby invalidating results of first call, leading to a program error. TOCTTOU errors in file system namespace generally deal with attempts to subvert file system permissions by tricking privileged program into either reducing permissions on privileged file or or modifying a privileged file to open up a security hole. Wei and Pu [2005] talk about TOCTTOU in UNIX file system.

**Filename and Pathname Truncation**

What happens if NAME_MAX is 14 and we try to create new file in current directoy with filename containing 15 characters? Traditionally, early releases of System V, allowed this to happen, silently truncating filename beyond the 14th character. BSD-derived systems, returned error status, with errno set to ENAMETOOLONG. Silently truncating filename presents a problem that affects more than simply creation of new files. If NAME_MAX is 14 and file exists whose name is exactly 14 characters, any function that accepts pathname argument, such as open or stat, has no way to determine what original name of file was, as original name might have been truncated.

POSIX.1, constant _POSIX_NO_TRUNC determines whether long filenames and long components of pathnames are truncated or an error is returned. Value can vary based on type of file system, we can use fpathconf or pathconf to query a directory to see which behaviour is supported.

If _POSIX_NO_TRUNC is in effect, errno is set to ENAMETOOLONG, and error status is returned if any filename component of pathname exceeds NAME_MAX. (Most modern file systems support maximum of 255 characters, so usually is not a problem).

## creat Function

New file can be created calling "creat" function:

```C
	#include <fcntl.h>
	int creat (const char *path, mode_t mode);
		Returns: file descriptor opened for write-only if OK, -1 on error.
```

This function is equivalent to:
```C
	open(path, O_WRONLY | O_CREAT | O_TRUNC, mode);
	As historically open only accepted 0, 1 or 2 as second argument, and it wasn't possible to open a non-existing file, creat was used. With O_CREAT and O_TRUNC provided by open, separate creat function no longer needed.
```

We'll see later the mode, when we describe file's access permission in detail. One deficiency with creat, file is opened only for writing. Before new version of open was provided, if we were creating temp file that we wanted to write and read, we had to call "creat", "close" and then "open". Better way is to use "open" function in this way:

```C
	open(path, O_RDWR | O_CREAT | O_TRUNC, mode);
```
## close Function

Open file is closed calling "close" function:

```C
	#include <unistd.h>
	int close (int fd);
		Returns 0 if OK, -1 on error
```

Closing a file, release any record locks that process may have on file. We'll discuss that further later.
When a process terminates, all of its open files are closed automatically by kernel. Many programs take advantage of this fact and don't explicitly close open files.

## lseek Function

Every open file has associated a "current file offset", a non-negative integer that measures number of bytes from the beginning of file (We'll see some exceptions to "non-negative" qualifier). Read and write operations normally start at current file offset and cause offset to be incremented by number of bytes read or written. By default, offset is 0 when file is opened, unless O_APPEND option is specified.
Open file's offset can be set calling "lseek":

```C
	#include <unistd.h>
	off_t lseek (int fd, off_t offset, int whence);
		Returns: new file offset if OK, -1 on error
```

Interpretation of offset depends on value of whence argument:

- if whence is SEEK_SET, file's offset is set to offset bytes from the beginning of the file.
- if whence is SEEK_CUR, file's offset is set to current value plus offset. Offset can be positive or negative.
- if whence is SEEK_END, file's offset is set to size of file plus offset. Offset can be positive or negative.

Because successful call to lseek returns new file offset, we can seek zero bytes from current position to determine current offset:

```C
	off_t	currpos;
	currpos = lseek(fd, 0, SEEK_CUR);
```

Technique can be used to determine if file is capable of seeking. If file descriptor refers to a pipe, FIFO, or socket, lseek sets errno to ESPIPE. (Three constants SEEK_SET, SEEK_CUR and SEEK_END were introduced in System V. Prior to this whence was 0 (absolute), 1 (relative to current offset), or 2 (relative to end of file). Character l in lseek means "long integer". Before introduction of off_t data type, offset argument and return value were long integers. lseek was added with Version 7 when long integers were added to C (previous to that the functions seek and tell were used)).

Example: *test_lseek.c* to see whether the standard input is capable of seeking. Here we can call the program giving different ways of input:

```console
	$ ./test_lseek < /etc/passwd # input is a file (seek OK)
	$ cat < /etc/passwd | ./test_lseek # input here is an string (cannot seek)
	$ ./test_lseek < /var/spool/cron/FIFO # input here is a FIFO (cannot seek)
```

A file's current offset must be a non-negative integer. It is possible, certain devices could allow negative offsets. But regular files, offset must be non-negative. Because negative offsets are possible, we should compare return of lseek with -1, and not if is lower than 0.

*lseek* only records current file offset within kernel, it does not cause any I/O to take place. This offset then sued by next read or write operation.

File's offset can be greater than file's current size, in which case next write to file will extend the file. This is referred to as creating a hole in a file and is allowed. Any bytes in a file that have not been written are read back as 0.

A hole in a file isn't required to have storage backing it on disk. Depending on file system implementation, when you write after seeking past end of a file, new disk blocks might be allocated to store the data, but there's no need to allocate disk blocks for data between old end of file and location where you start writing.

Example: *file_hole.c* example that creates a file with a hole in it. We can see with "ls -l file.hole" the size of the file, and then with "od -c file.hole" the content of the file. The flag -c of "od" command tells to print the contents as characters. Unwritten bytes in the middle are read back as zero. The seven-digit number at the beginning of each line is the byte offset in octal.

Because offset address that lseek uses is an off_t, implementations are allowed to support whatever size is appropiate on their particular platform. Most platforms today provide two sets of interfaces to manipulate file offsets: one that uses 32-bit file offsets and another that uses 64-bit file offsets.

Single UNIX specification provides a way for applications to determine which environments are supported through sysconf function. Figure 3.3 in page 70, gives a set of Name of option and description of types depending on the system.
c99 compiler requires that we use getconf(1) command to map desired data size model to flags necessary to compile and link our programs. Different flags and libraries might be needed, depending on environments supported by each platform.
Applications can set _FILE_OFFSET_BITS constant to 64 to enable 64-bit offsets. Doing so changes definition of off_t to be 64-bit signed integer. Setting _FILE_OFFSET_BITS to 32 enables 32-bit file offsets. This technique is not guaranteed to be portable.

Different versions as Figure 3.4 of page 70 shows, can have different values if _FILE_OFFSET_BITS is set or not.
Even though you might enable 64-bit file offsets, ability to create a file larger than 2GB (2^31 -1 bytes) depends on underlying file system type.


## read Function

Data read from open file with read function

```C
	#include <unistd.h>
	ssize_t read(int fd, void *buf, size_t nbytes);
		Returns: number of bytes read, 0 if end of file, -1 on error
```

If read is successful, number of bytes read is returned. If end of file is encountered, 0 is returned.
Several cases in which number of bytes actually read is less than aument requested:

* When reading from regular file, if end of file is reached before requested number of bytes has been read. Example, 30 bytes remain until end of file and we try to read 100 bytes, read returns 30. Next time will return 0.
* Reading from a terminal device. Normally, one line is read at a time.
* When reading from network. Buffering within network may cause less than requested amount to be returned.
* When reading from a pipe or FIFO. If pipe contains fewer bytes than requested, read will return only what is available.
* When reading from record-oriented device. Some of them such as magnetic tape, can return up to single record at a time.
* Interrupted by a signal and partiaul amount of data has already been read.

Read operation starts at file's current offset. Before successful return, offset is incremented by number of bytes actually read.
POSIX.1 changed prototype for function in several ways, classic definition:

```C
	int read (int fd, char *buf, unsigned nbytes);
```
* Second argument changed from char * to void *, to be consistent with ISO C: type void * is used for generic pointers.
* Return value was required to be signed integer (ssize_t) to return positive byte count, 0 (end of file), or -1 (for error)
* Finally historically third argument was unsigned integer, to allow 16-bit implementation to read or write up to 65,534 bytes at a time. With 1990 POSIX.1, primitive system data type ssize_t was introduced, to provide signed return value, and unsigned size_t was used for third argument.

## write Function

Data written to open file with write function:

```C
	#include <unistd.h>
	ssize_t write (int fd, const void *buf, size_t nbytes);
		Returns: number of bytes written if OK, -1 on error
```

Return value usally equal to nbytes argument; otherwise error has occurred. Common cause for write error is filling up a disk or exceeding file size limit for given process.

For regular file, write operation starts at file's current offset. If O_APPEND option was specified, file's offset is set to current end of file before each write operation. After successful write, file's offset is incremented by number of bytes actually written.

## I/O Efficiency

Example: *copy_file.c*, uses only read and write functions. Following caveats apply to the program:
* Reads from standard input and writes to standard output assuming these have been set up by shell before program is executed. Indeed, all normal UNIX system shells provide way to open file for reading on standard input and to create (or rewrite) file on standard output. Prevents program from having to open input and output files, and allows user to take advantage of shell's I/O redirection facilities.
* Program doesn't close input file or output file. Program uses feature of UNIX kernel that closes all open file descriptors in process when process terminates.
* Example works for both text files and binary files, since there's no difference between both to UNIX kernel.

Some tests were done with BUFFSIZE, program was run with different values of BUFFSIZE to check the User CPU (in seconds), System CPU (in seconds), clock time (in seconds) and number of loops.

File was read using previous program, with output redirected to /dev/null. File system used was a Linux with ext4 file system with 4,096 blocks. This makes that minimum time ocurring at the few timing measurements starting around a BUFFSIZE of 4,096. Increasing buffer size beyond limit has little positive effect.

Most file systems support read-ahead to improve performance. When sequential reads are detected, system tries to read-ahead than application request, assuming application will read it shortly. Effect of read-ahead can be seen in timing tables, where with a small buffer of 32 bytes system start to improve times because of read-ahead.
We'll see the effect of synchronous writes; later we will compare unbuffered I/O times with standard I/O library.

## File Sharing

UNIX System supports sharing of open files among different processes. Before describing dup function, we need to describe this sharing. We'll examine data structures used by kernel for all I/O.
The kernel uses three data structures to represent an open file, and relationship among them determine effect one process has on another with regard to file sharing.

1. Every process has entry in process table. Within each process table entry is a table of open file descriptors, which we can think of as a vector, with one entry per descriptor. Associated with each file descriptor are:
	* file descriptor flags (close-on-exec)
	* pointer to a file table entry
2. Kernel maintains file table for all open files. Each file table entry contains:
	* file status flags for file, such as read, write, append, sync, and nonblocking.
	* current file offset.
	* pointer to v-node table entry for the file
3. Each open file (or device) has v-node structure that contains information about type of file and pointers to functions that operate on the file. For most files, v-node also contains i-node for the file. Information is read from disk when file is opened, so all the pertinent information about file is readily available. Example, i-node contains owner of the file, size of the file, pointers to where actual data blocks for file are located on disk. (Linux has no v-node. Instead, generic i-node structure is used. Although implementations differ, v-node is conceptually the same as generic i-node. Both point to an i-node structure specific to file system).
We're ignoring implementation details don't affect our discussion. Example, table of open file descriptors can be stored in user area (a separate process structure that can be paged out) instead of process table. Also, these tables can be implemented in numerous ways, do not need to be arrays; another alternate implementation is a linked list of structures. Concepts remain the same.
Figure 3.7 of page 75 shows pictorial arrangement of these three tables for single process that has two different files open: one file is open on standard input (file descriptor 0), and other is open on standard output (file descriptor 1).

<img src="https://notes.shichao.io/apue/figure_3.7.png">

Arrangement of three tables has existed since early versions of UNIX system. Arrangement is critical to the way files are shared among processes. We'll return to table when we describwe additional ways that files are shared.
(v-node was invented to provide support for multiple file system types on single computer system. This was done by Peter Weinberger and Bill Joy. Sun called this Virtual File System and called the file system-independent portion of the i-node the v-node. v-node propagated through various vendor implementations as support for Sun's Network File System (NFS) was added. First release from Berkeley to provide v-node was 4.3BSD Reno release, when NFS was added. In SVR4, v-node replaced file system-independent i-node of SVR3. Solaris is derived from SVR4 and uses v-nodes. Instead of splitting data structures into v-node and i-node, Linux uses file system-independent i-node and a file system-dependent i-node.)

If two independent process have same file open, we could have as Figure 3.8 in page 76, where each process table entry (in user process) points to a different file table entry (in kernel) but finally each v-node pointer points to same v-node table entry and this to same i-node.

<img src="https://notes.shichao.io/apue/figure_3.8.png">

In example we see that first process has file open on descriptor 3, and other process in descriptor 4. So as we said each process has its own file table entry, but only single v-node is required. One reason why each process has its own file table entry is because each process has its own current file offset for file.
Given these data structures, now need to be more specific about what happens with certain operations that we've described.

* After write is complete, current file offset in file table entry is incremented by number of bytes written. If causes current file offset to exceed current file size, current file size in i-node table entry is set to current file offset (file is extended).
* If file is opened with O_APPEND flag, corresponding flag is set in file status flags of file table entry. Each time a write is performed for a file with this flag set, current file offset in file table entry is first set to current file size from i-node table entry. Forces every write to be appended to current end of file. (IMPORTANT FOR LATER)
* If file is positioned to current end of file using lseek, all that happens is current file offset in file table entry is set to current file size from i-node table entry. (Not the same that using flag O_APPEND)
* lseek function modifies only current file offset in file table entry. No I/O takes place.

It's possible for more than one file descriptor entry, point to same file table entry, as we'll see with "dup" function. This also happens after a "fork" when parent and child share same file table entry for each open descriptor.

Note difference in scope between file descriptor flags and file status flags. Former apply only to single descriptor in single process, whereas latter apply to all descriptors in any process that point to given file table entry. When we describe fcntl function in Section 3.14, we'll see how to fetch and modify both, file descriptor flags and file status flags.

Everything described in this section works fine for multiple processes that are reading same file. Each process has its own file table table entry with its own current file offset. Unexpected results can arise, when multiple processes write to same file. We need to understand concept of atomic operations.

## Atomic Operations

Appending to a File: consider single process that wants to append to end of a file. Older versions of UNIX System didn't support O_APPEND option, so program was like this:

```C
	if (lseek (fd, 0L, 2) < 0)	/* position to EOF */
		err_sys("lseek error");
	if (write (fd, buf, 100) != 100)	/* and write */
		err_sys("write error");
```

Works fine for single process, but there are problems if multiple process use this technique to append to same file (example multiple instances of same program are appending messages to log file).

Assume two independent processes, A and B, are appending to same file. Each has opened the file but without O_APPEND flag. This gives us same picture as Figure 3.8. Each process has its own file table entry, but they share a single v-node table entry. Assume process A does lseek and sets current offset for file for process A to byte offset 1,500 (current end of file). Then kernel switches processes, and B continues running. Process B then does lseek, which sets current does lseek, which sets current offset for file for process B to byte offset 1,500 also (current end of file). Then B calls write, which increments B's current file offset for file to 1,600. Because file's size has been extended, kernel also updates current file size in v-node to 1,600. Then kernel switches processes and A resumes. When A calls write, data is written starting at current file offset for A, which is byte offset 1,500. This overwrites data that B wrote to the file (because without O_APPEND current file offset is not updated to i-node current file size).

Problem, is that logical operation of "position to the end of file and write" requires two separate function calls. Solution is to have positioning to current end of file and write be an atomic operation with regard to other processes. Any operation that requries more than one function call cannot be atomic, as kernel might temporarily suspend process between two function calls.

The UNIX System provides atomic way to do this operation if we set the O_APPEND flag when file is opened. This causes kernel to position the file to its current end of file before each write. We no longer have to call lseek before each write.

**pread and pwrite Functions**

UNIX specification includes two functions, allow applications to seek and perform I/O atomically: pread and pwrite.

```C
	#include <unistd.h>

	ssize_t pread(int fd, void *buf, size_t nbytes, off_t offset);
		Returns: number of bytes read, 0 if end of file, -1 on error

	ssize_t pwrite(int fd, void *buf, size_t nbytes, off_t offset);
		Returns: number of bytes written if OK, -1 on error.
```

Calling pread = calling lseek + read, with exceptions:
* There's no way to interrupt two operations that occur when we call pread.
* Current file offset is not uploaded.

Calling pwrite = calling lseek + write with similar exceptions.

**Creating a File**

We saw another atomic operation when we described O_CREAT and O_EXCL options for open. When both exist, open will fail if file already exists. We said check for existence of file, and creation of file was performed as atomic operation. Without that atomic operation we had to do:

```C
	if (( fd = open(path, O_WRONLY) ) < 0) {
		if (errno == ENOENT) {
			if (( fd = creat(path, mode)) < 0 )
				err_sys("creat error");
		} else {
			err_sys("open error");
		}
	}
```

But there's a problem if a process create the file between open and creat calls. If that happens and the other process writes something, content will be erased with creat function. For that reason combining test for existence and creation into single atomic operation avoids problem.

Atomic operation refers to operation that might be composed of multiple steps. If operation is atomic, all the steps are performed (success) or none are performed (failure). We'll again see atomic operations with the function link.

## dup and dup2 Functions

Existing file descriptor is duplicated with this functions:

```C
	#include <unistd.h>

	int dup (int fd);
	int dup2 (int fd, int fd2);
		Both return: new file descriptor if OK, -1 on error
```

New file descriptor returned by dup, guaranteed to be lowest-numbered available file descriptor. With dup2, we specify the new descriptor with fd2 argument (example we can specify a socket as first argument, and stdin, stdout and stderr as second argument). If fd2 is open, it's first closed. If fd == fd2, dup2 returns fd2 without closing it. Otherwise, FD_CLOEXEC file descriptor flag, cleared for fd2, so fd2 is left open if process calls exec.

New file descriptor returned as value of functions shares same file table entry (the one from kernel) as fd argument.
<img src="https://notes.shichao.io/apue/figure_3.9.png">

In Figure 3.9 (page 80), we assume that at beginning of program executes:

```C
	newfd = dup(1);
```

So probably, if no file was opened, next available descriptor is 3 (0, 1 and 2 are opened by the shell). And as both point same file table entry, share file status flags, current file offset and v-node pointer. The descriptor flag close-on-exec is cleared by dup functions always.

fcntl function can be used to duplicate dup and dup2:

```C
dup(fd)      	=	fcntl(fd, F_DUPFD, 0)

dup2(fd, fd2)	=	close(fd2)
			        fcntl(fd, F_DUPFD, fd2)
```

This last one is not the same, because dup2, is atomic, but close followed by fcntl isn't. This can be a proble if there's a signal between both or there's a different thread.

Also there are some errno differences between dup2 and fcntl.

## sync, fsync, and fdatasync Functions

Implementations of UNIX System have buffer cache or page cache in kernel through which most disk I/O passes. When we write data to a file, data is normally copied by kernel into one of its buffer and queued for writing to disk at some later time. This is "delayed write".
Kernel eventually writes all delayed-write blocks to disk, normally when it needs to reuse buffer for some other disk block. The explained three functions are used to ensure consistency of file system on disk with contents of buffer cache.

```C
	#include <unistd.h>

	int fsync(int fd);
	int fdatasync(int fd);
		Returns: 0 if OK, -1 on error
	void sync(void);
```

sync function simply queues all modified block buffers for writing and returns; it does not wait for disk writes to take place.

Function sync called periodically ( ~30 seconds ) from system daemon (called update). This guarantees regular flushing of kernel's block buffers. Command sync also calls sync function.
Function fsync refers only to single file, specified by file descriptor fd, waits for disk writes to complete before returning. Function is used when application, such as database, needs to be sure, modified blocks have been written to disk.

The fdatasync function similar to fsync, but it affects only data portions of a file. With fsync, file's attributes are also updated synchronously.

## fcntl Function

it can change properties of a file that is already open.

```C
	#include <fcntl.h>
	int fcntl(int fd, int cmd, ... /* int arg */ );
		Return: depends on cmd if OK, -1 on error
```

In examples, third argument is always an integer. When we describe record locking in section 14.3, third argument will become a pointer to a structure. fcntl function used for five different purposes:

* Duplicate existing descriptor (cmd = F_DUPFD or F_DUPFD_CLOEXEC)
* Get/set file descriptors flags (cmd = F_GETFD or F_SETFD)
* Get/set file status flags (cmd = F_GETFL or F_SETFL)
* Get/set asynchronous I/O ownership (cmd = F_GETOWN or F_SETOWN)
* Get/set record locks (cmd = F_GETLK, F_SETLK or F_SETLKW)

Let's describe the first 8 of 11 cmd values.

* *F_DUPFD*: duplicate file descriptor fd. New file descriptor returned as value of the function. It is lowest-numbered descriptor not already open, and is greater than or equal to the third argument (an integer), new filedescriptor share same file table entry as fd. New descriptor has its own set of file descriptor flags, and its FD_CLOEXEC file descriptor flag is cleared (descriptor is lef open across an exec).
* *F_DUPFD_CLOEXEC*: Same as before, but this time set the FD_CLOEXEC file descriptor flag in new descriptor.
* *F_GETFD*: return file descriptor flags for fd as value of function. Currently, only one file descriptor flag is defined FD_CLOEXEC flag.
* *F_SETFD*: Set file descriptor flags for fd. New flag value is set from third argument.
* *F_GETFL*: Return file status flags for fd as value of the function. We described file status flags when described open, here is a sumary:
	* *O_RDONLY*: open only for reading
	* *O_WRONLY*: open only for writing
	* *O_RDWR*: open for reading-writing
	* *O_EXEC*: open for execute only
	* *O_SEARCH*: open directory for searching only
	* *O_APPEND*: append on each write
	* *O_NONBLOCK*: nonblocking mode
	* *O_SYNC*: wait for writes to complete (data and attributes.
	* *O_DSYNC*: wait for writes to complete (data only)
	* *O_RSYNC*: synchronize reads and writes
	* *O_FSYNC*: wait for writes to complete (FreeBSD and MacOSX)
	* *O_ASYNC*: asynchronous I/O.

	Problem that the first 5 are not separate bits that can be tested (example the first 3 have the values 0,1, and 2 for historical reasons. Also, these five values are mutually exclusive). We must first use O_ACCMODE mask to obtain the access-mode bits and then compare result against any of five values.

* *F_SETFL*: set file status flags to value of third argument. The only flags that can be changed are O_APPEND, O_NONBLOCK, O_SYNC, O_DSYNC, O_RSYNC, O_FSYNC and O_ASYNC.
* *F_GETOWN*: Get process ID or process group ID currently receiving SIGIO and SIGURG signals. We'll see in chapter 14.
* *F_SETOWN*: Set process ID or process group ID to receive SIGIO and SIGURG signals. Positive arg specifies a process ID. A negative arg implies a process group ID equal to absolute value of arg.

Return value from fcntl depends on command. All commands return -1 on error or some other value if OK. Following four: F_DUPFD, F_GETFD, F_GETFL, and F_GETOWN. First returns new file descriptor, next two return corresponding flags, and final returns positive process ID or negative process group ID.

Example: check_file_descriptor_flags.c example program where we use fcntl to check the file flags of the file descriptors. Let's see the checks:

```console
	$ ./program 0 < /dev/tty # opens /dev/tty as stdin
	read only
	$ ./program 1 > temp.foo # opens temp.foo as stdout
	$ cat temp.foo
	write only
	$ ./program 2 2>>temp.foo # opens temp.foo as stderr appending data
	write only, append
	$ ./program 5 5<>temp.foo
	read write
```

The clause 5<>temp.foo opens file temp.foo for reading and writing on descriptor 5.

Example: If we modify file descriptor flags or file status flags, we must fetch existing flag value, modify it as desired, and set new flag value. We can't simply issue F_SETFD or F_SETFL command. Next is a function to set one or more of file status flags for a descriptor.

```C
	#include "apue.h"
	#include <fcntl.h>

	void
	set_fl (int fd, int flags) /* flags are file status flags to turn on */
	{
		int	val;

		if ((val = fcntl(fd, F_GETFL, 0)) < 0)
			err_sys("fcntl F_GETFL error");

		val |= flags;	/* turn on flags */

		if (fcntl(fd, F_SETFL, val) < 0)
			err_sys("fcntl F_SETFL error");
	}
```

But if we change middle statement to:

```C
	#include "apue.h"
	#include <fcntl.h>

	void
	clr_fl (int fd, int flags)
	{
		int	val;

		if ((val = fcntl(fd, F_GETFL, 0)) < 0)
			err_sys("fcntl F_GETFL error");

		val &= ~flags;		/* turn flags off */

		if (fcntl(fd, F_SETFL, val) < 0)
			err_sys("fcntl F_SETFL error");
	}
```

Using the AND operation, and the complement of flags, we can reset the previous values of val.

Adding line:

```C
	set_fl(STDOUT_FILENO, O_SYNC);
```

to the beginning of program shown in Figure 3.5, we'll turn on synchrnous-write flag. So this would make each write to wait for the data to be written to disk before returning. As UNIX System, write only queues data for writing; actual disk write can take place sometime later. Database system, likely candidate for using O_SYNC, so that it knows on return from a write that data is actually on disk, in case of abnormal system failure.
O_SYNC flag increase system and clock times when program runs.

## ioctl Function

The alfa and the omega of I/O operations. So anything that couldn't be expressed using one of the other functions in this chapter usually ended up being specified with an ioctl. Terminal I/O was biggest user of this function (We'll see in chapter18, that many of this operations has been replaced with separated functions).

```C
	#include <unistd.h>		/* System V */
	#include <sys/ioctl.h>		/* BSD and Linux */

	int ioctl(int fd, int request, ... );
		Returns: -1 on error, something else if OK

	ioctl was included in Single UNIX Specification only as extension for dealing with STREAMS devices, but it was moved to obsolescent status in SUSv4. UNIX System implementations use ioctl for many miscellaneous device operations.
```

Showed property corresponds to POSIX.1. FreeBSD 8.0 and Mac OS X 10.6.8, declare second argument as unsigned long. This doesn't matter, since second argument is always a #defined name from a header.

For ISO C prototype, an ellipsis is used for remaining arguments. Normally, however, there is only one more argument, usually a pointer to a variable or a structure.

In this prototype, we show only headers required for function itself. Normally, additional device-specific headers are required. Example, ioctl commands for terminal I/O, beyond basic operations specified by POSIX.1, all require <termios.h> (instead of <sys/termios.h> that is deprecated).

Each, device driver can define its own set of ioctl commands. System however, provides generic ioctl commands for different classes of devices. Here example of ioctls, with category, constant names, header and number:
```
	disk labels	    DIOxxx	    <sys/disklabel.h>	4
	file I/O	    FIOxxx	    <sys/filio.h>		14
	mag tape I/O	MTIOxxx	    <sys/mtio.h>		11
	socket I/O	    SIOxxx	    <sys/sockio.h>		73
	terminal I/O	TIOxxx	    <sys/ttycom.h>		43
```
The mag tape operations allow us to write end-of-file marks on a tape, rewind a tape, space forward... None of these operations is easily expressed in terms of other functions (like read, write, lseek, etc), so easiest way to handle these has always been to access their operations using ioctl.
We use ioctl in chapter 18 to fetch and set size of terminal's window, and in chapter 19 when we access advanced features of pseudo terminals.

## /dev/fd

Newer systems provide directory named /dev/fd, whose entries are files named 0, 1, 2 and so on. Opening file /dev/fd/n is equivalent to duplicating descriptor n, assuming that descriptor n is open.
Example:

```C
	fd = open("/dev/fd/0", mode);
```

most systems ignore specified mode, whereas others require that it be a subset of mode used when referenced file (stdin in this case) was originally opened.
Because previous open is equivalent to:

```C
	fd = dup(0);
```

descriptors 0 and fd share same file table entry. If descriptor 0 was opened read-only, we can only read on fd. Even if system ignores open mode and the call:

```C
	fd = open("/dev/fd/0", O_RDWR);
```

succeeds, we still can't write to fd. (Linux when you open /dev/fd/0 what it does is to map a symbolic link to underlying physical files).

We can also call creat, as well as specify O_CREAT in a call to open. Beware of doing this on Linux, as it uses symbolic links to real files, using creat will result in underlying file being truncated.

Other systems provide pathnames /dev/stdin, /dev/stdout and /dev/stderr. Equivalent to /dev/fd/0, /dev/fd/1 and /dev/fd/2.

Main use of /dev/fd files is from shell. Allows that use pathname arguments to handle standard input and standard output in same manner as other pathnames. Example, cat program looks for an input filename of - and uses it to mean standard input:

```console
	filter file2 | cat file1 - file3 | lpr
```

First cat reads file1, then its standard input (output of filter program on file2), and then file3. If /dev/fd is supported, special handling of - can be replaced by:

```console
	filter file2 | cat file1 /dev/fd/0 file3 | lpr
```
